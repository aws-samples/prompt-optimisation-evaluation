{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r sentiment_categorisation_prompt_id\n",
    "%store -r sentiment_categorisation_prompt_arn\n",
    "%store -r summarisation_prompt_id\n",
    "%store -r summarisation_prompt_arn\n",
    "%store -r extraction_prompt_id\n",
    "%store -r extraction_prompt_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langfuse\n",
    "\n",
    "Provides Observability/tracking, UI for inspection, Prompt Management and playground to test LLMs and prompts, monitoring/analytics (alpha), evaluation pipeline and user feedback management.\n",
    "\n",
    "More info here:\n",
    "https://langfuse.com/docs\n",
    "\n",
    "(Tests done with Langfuse 2.65.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy locally (recommended) or use the SaaS version\n",
    "\n",
    "How to deploy Locally: https://langfuse.com/docs/deployment/local\n",
    "\n",
    "Otherwise, sign up for an account there: https://langfuse.com/\n",
    "\n",
    "For those who want to deploy it on AWS, Aaron Su developed a CDK for that: https://github.com/aaronsu11/langfuse-on-aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new project and add a new API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../static/langfuse/langfuse1.png\" width=\"800px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langfuse==2.39.3\n",
    "!pip install -q boto3==1.34.149\n",
    "!pip install -q langchain==0.2.11 \n",
    "\n",
    "!pip install -q langchain-community==0.2.10\n",
    "!pip install -q -U langchain-aws==0.1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "#adding our utils library to sys path\n",
    "import sys\n",
    "sys.path.append(\"../src/utils/\")\n",
    "import llm_utils\n",
    "\n",
    "session = boto3.Session()\n",
    "bedrock_runtime_client = session.client(service_name='bedrock-runtime')\n",
    "bedrock_client = session.client(service_name='bedrock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a locally deployed version for this workshop but feel free to use the SaaS version if easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve prompts from Bedrock prompt template management for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "\n",
    "#retrieve the prompt for test\n",
    "sentiment_prompt_info = bedrock_agent_client.get_prompt(\n",
    "    promptIdentifier=sentiment_categorisation_prompt_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables_sentiment = sentiment_prompt_info['variants'][0]['templateConfiguration']['text']['inputVariables']\n",
    "prompt_template_sentiment = sentiment_prompt_info['variants'][0]['templateConfiguration']['text']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_variables_sentiment)\n",
    "print(prompt_template_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing & Observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load transcripts from generated folder to use in our tests\n",
    "transcripts = llm_utils.load_jsonlines_file(\"../generated/transcripts/transcripts.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with your own. we're using a locally deployed instance in this workshop\n",
    "secret_key=\"sk-lf-eb802559-2518-419c-bcec-b6dc71d4e6ea\"\n",
    "public_key=\"pk-lf-b8e69cf7-03c1-4411-bc0c-c7f8f3feb55b\"\n",
    "host=\"http://localhost:3000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "#used for low level python APIs\n",
    "langfuse_client = Langfuse(\n",
    "  secret_key=secret_key,\n",
    "  public_key=public_key,\n",
    "  host=host\n",
    ")\n",
    "\n",
    "#used as a callback handler in the langchain API\n",
    "langfuse_handler = CallbackHandler(\n",
    "   secret_key=secret_key,\n",
    "  public_key=public_key,\n",
    "  host=host\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Langchain as a wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "max_tokens = 400\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model_id=model_id,\n",
    "    max_tokens = max_tokens,\n",
    "    temperature = temperature,\n",
    "    top_p = top_p\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the below code does not work because the The parent_run_id attribute was introduced in a recent version of LangChain and the version of langfuse is not supporting it. it might work by the time you're running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\": \"bears\"}, config={\"callbacks\": langfuse_handler})\n",
    "response\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative option using the 0.1x APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "prompt = PromptTemplate(input_variables=input_variables_sentiment, template=prompt_template_sentiment)\n",
    "\n",
    "# Create the chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "example_transcript = transcripts[0]['transcript']\n",
    "\n",
    "output = chain.run(transcript=example_transcript, callbacks=[langfuse_handler])\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES: When checking your trace in the UI, make sure you navigate the tree on the right hand side to display all nested information.\n",
    "\n",
    "<img src = \"../static/langfuse/langfuse_trace.png\" width=800px />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the low level python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generation in Langfuse\n",
    "generation = langfuse_client.generation(\n",
    "    name=\"sentiment-generation\",\n",
    "    model=model_id,\n",
    "    model_parameters={\"maxTokens\": max_tokens, \"temperature\": temperature, \"topP\": top_p},\n",
    "    input=[{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": prompt.format(transcript=example_transcript)}],\n",
    "    metadata={\"interface\": \"jupyter notebook\"}\n",
    ")\n",
    "\n",
    "output = chain.run(transcript=example_transcript)\n",
    " \n",
    "# Update span and sets end_time\n",
    "generation.end(output=output)\n",
    "\n",
    "# To ensure that all requests are sent before the process exits, call flush()\n",
    "langfuse_client.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES: notice the slightly different trace tree structure and where the information is stored.\n",
    "\n",
    "<img src = \"../static/langfuse/langfuse_trace2.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reminder of our test prompt info\n",
    "sentiment_prompt_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat prompt\n",
    "langfuse_prompt = langfuse_client.create_prompt(\n",
    "    name=sentiment_prompt_info['name'],\n",
    "    type=\"chat\",\n",
    "    prompt=[{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": prompt_template_sentiment.format(transcript=example_transcript)}],\n",
    "    labels=[\"staging\"],\n",
    "    config={\n",
    "        \"model\": model_id,\n",
    "        \"temperature\": temperature,\n",
    "        \"supported_languages\": [\"en\"],\n",
    "        \"aws_arn_equivalent\" : sentiment_prompt_info['arn']  # FYI, you can add any kind of metadata to the prompt\n",
    "    },  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"../static/langfuse/langfuse_prompt.png\" width=800px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current production version of a chat prompt\n",
    "chat_prompt = langfuse_client.get_prompt(sentiment_prompt_info['name'], \n",
    "                                         type=\"chat\", # type arg infers the prompt type (default is 'text')\n",
    "                                         label=\"staging\", #not needed if you get a production prompt\n",
    "                                         fallback=[{\"role\": \"system\", \"content\": \"Default prompt\"}]) #useful if somehow the service is not responding\n",
    "print(chat_prompt.prompt)\n",
    "print(chat_prompt.config)\n",
    "print(chat_prompt.is_fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert variables into chat prompt template\n",
    "compiled_chat_prompt = chat_prompt.compile(transcript=example_transcript)\n",
    "compiled_chat_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt integration with the generation trace api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = langfuse_client.generation(\n",
    "    name=\"sentiment-generation\",\n",
    "    prompt = chat_prompt,  #added\n",
    "    model=model_id,\n",
    "    model_parameters={\"maxTokens\": max_tokens, \"temperature\": temperature, \"topP\": top_p},\n",
    "    input=[{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": compiled_chat_prompt}],\n",
    "    metadata={\"interface\": \"jupyter notebook\"}\n",
    ")\n",
    "\n",
    "output = chain.run(transcript=example_transcript)\n",
    " \n",
    "# Update span and sets end_time\n",
    "generation.end(output=output)\n",
    "\n",
    "# To ensure that all requests are sent before the process exits, call flush()\n",
    "langfuse_client.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"../static/langfuse/langfuse_prompt_int.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual scoring UI\n",
    "\n",
    "More info here: https://langfuse.com/docs/scores/annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES: \n",
    "- You need to manually create your category, nothing out of the box with the \"free\" version.\n",
    "- no tasks, queue management for annotations of generations.\n",
    "\n",
    "<img src = \"../static/langfuse/langfuse_eval.png\" width=800px />\n",
    "\n",
    "\n",
    "<img src = \"../static/langfuse/langfuse_eval2.png\" width=800px />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User feedbacks at chatbot level via their LangfuseWeb SDK\n",
    "\n",
    "https://langfuse.com/docs/scores/user-feedback\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated scoring/evaluation capabilities\n",
    "\n",
    "This seems to be done primarily via integration of external solutions/libraries and the output is stored in langfuse for the record.\n",
    "\n",
    "See below an example with langchain evaluation libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we start by fetching the generations\n",
    "def fetch_all_pages(name=None, user_id = None, limit=50):\n",
    "    page = 1\n",
    "    all_data = []\n",
    " \n",
    "    while True:\n",
    "        response = langfuse_client.get_generations(name=name, limit=limit, user_id=user_id, page=page)\n",
    "        if not response.data:\n",
    "            break\n",
    " \n",
    "        all_data.extend(response.data)\n",
    "        page += 1\n",
    " \n",
    "    return all_data\n",
    "\n",
    "\n",
    "generations = fetch_all_pages(name=\"sentiment-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "def execute_eval_and_score(llm, eval_criteria, langfuse_client):\n",
    "  \n",
    "  for generation in generations:\n",
    "    for criterion in eval_criteria:\n",
    "\n",
    "      #get evaluator based on criteria?\n",
    "      evaluator = load_evaluator(\"criteria\", criteria=criterion, llm=llm)\n",
    "\n",
    "      #evaluate output\n",
    "      if (generation.input and generation.output):\n",
    "        eval_result = evaluator.evaluate_strings(\n",
    "            prediction=generation.output,\n",
    "            input=generation.input,\n",
    "        )\n",
    "        \n",
    "        print(f\"criterion: {criterion} : {eval_result[\"score\"]}\")\n",
    "  \n",
    "        #call langfuse api to store the score/reasoning alongside the generation.\n",
    "        langfuse_client.score(name=criterion, trace_id=generation.trace_id, observation_id=generation.id, value=eval_result[\"score\"], comment=eval_result['reasoning'])\n",
    "\n",
    "        langfuse_client.flush()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_criteria = [\"relevance\", \"coherence\"]\n",
    "\n",
    "execute_eval_and_score(llm, eval_criteria, langfuse_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"../static/langfuse/langfuse_eval3.png\" width=800px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_dev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
